{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba40c18d",
   "metadata": {},
   "source": [
    "<font color='Orange'> <h2> NLP Project </h2> </font>\n",
    "## Project Title: Sentiment Analysis and Topic Modelling on Hotel Reviews\n",
    "#### Author: \n",
    "- Hemanth Mydugolam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b38c80",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    " # Table of Contents  \n",
    "[Part 1: Sentiment Analysis](#1)     \n",
    "1. [Import the required libraries such as Pandas, NLTK, and Scikit-learn.](#11)\n",
    "1. [Load the reviews data file and examine](#12)\n",
    "1. [Cleaning the data](#13)\n",
    "1. [Data Analyzing.](#14)\n",
    "1. [EDA - Data Visualization](#15)\n",
    "1. [Data Preparation for sentiment Analysis (Stop words removal, special characters removal and tokenization](#16)\n",
    "1. [Sentiment Analysis: NLTK](#17)\n",
    "\n",
    "[Part 2: Topic Modelling](#2)\n",
    "1. [Load the required libraries](#21) \n",
    "1. [Use the same reviews dataset as the input file](#22)\n",
    "1. [Preprocess the reviews data (removing stop words, tokenization,stemming, and lemmatization)](#23) \n",
    "1. [Latent Dirichlet Allocation - LDA Approach](#24)\n",
    "    1. [Positive Reviews - LDA](#241)\n",
    "    1. [Negative Reviews - LDA](#242)    \n",
    "\n",
    "[Part 3: Deep dive into particular Hotel on best and worst reviewed Hotel](#3)\n",
    "1. [Based on EDA Results](#31) \n",
    "1. [Data preparation on choosen Hotel](#32) \n",
    "1. [Topic Modelling on subset data](#33) \n",
    "    1. [Positive Reviews Data preparation for LDA](#331)\n",
    "    1. [Negative Reviews Data preparation for LDA](#332)\n",
    "1. [Topics visualization using pyLDAvis](#34) \n",
    "\n",
    "[Part 4: Insights](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32804dc",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "## Part 1: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f084387e",
   "metadata": {},
   "source": [
    "<a id=\"11\"></a> \n",
    "### 1.1 Import the required libraries such as Pandas, NLTK, and Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d8e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Import the required libraries\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from numpy import newaxis\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "#import tensorflow_text\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Activation, GRU, BatchNormalization\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence, text\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12, 8\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a65626",
   "metadata": {},
   "source": [
    "<a id=\"12\"></a> \n",
    "### 1.2 Load the reviews data file and examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Load the reviews data file\n",
    "df_h = pd.read_csv(\"Hotel_Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_h.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aec1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64083cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3629c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b64f1",
   "metadata": {},
   "source": [
    "<a id=\"13\"></a> \n",
    "### 1.3 Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658293a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88979cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Cleaning the data\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb38ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining both Positive and Negative reviews\n",
    "df['Combined_Review'] = df.Positive_Review + df.Negative_Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to reviews\n",
    "df['Cleaned_Review'] = df['Combined_Review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5eca515",
   "metadata": {},
   "source": [
    "<a id=\"14\"></a> \n",
    "### 1.4 Data Analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09bec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de31ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='object').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6417c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviwer Score distribution\n",
    "print(df['Reviewer_Score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7ab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Positive word count {df.Review_Total_Positive_Word_Counts.sum()}, Total negative word count {df.Review_Total_Negative_Word_Counts.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Hotels and Bottom Hotels\n",
    "top_hotels = df.groupby('Hotel_Name')['Average_Score'].mean().nlargest(10)\n",
    "top_hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_hotels = df.groupby('Hotel_Name')['Average_Score'].mean().nsmallest(10)\n",
    "bottom_hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8840818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal Analysis\n",
    "df['Review_Date'] = pd.to_datetime(df['Review_Date'])\n",
    "df.set_index('Review_Date', inplace=True)\n",
    "monthly_average_scores = df.resample('M')['Average_Score'].mean()\n",
    "monthly_average_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74895b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nationality-based Analysis\n",
    "nationality_scores = df.groupby('Reviewer_Nationality')['Reviewer_Score'].mean().sort_values(ascending=False)\n",
    "nationality_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe5fce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags Analysis\n",
    "tags = df['Tags'].str.split(',').explode().str.strip()\n",
    "tag_counts = tags.value_counts()\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba48161",
   "metadata": {},
   "source": [
    "<a id=\"15\"></a> \n",
    "### 1.5 EDA - Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515bad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"Reviewer_Score\", title=\"Review Score Distribution\", nbins=20, text_auto=True)\n",
    "\n",
    "# Change the color of the distribution bars\n",
    "color_sequence = ['#255d84'] * 24  # You can replace this with your preferred color or use a different color sequence\n",
    "fig.update_traces(marker=dict(color=color_sequence))\n",
    "\n",
    "# Rename x-axis and y-axis titles\n",
    "fig.update_xaxes(title_text=\"Reviewer Score\")\n",
    "fig.update_yaxes(title_text=\"Count of Reviews\")\n",
    "\n",
    "# Center the title\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Review Score Distribution\", font=dict(size=20, color='black')),\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"Average_Score\", title='Review Average Score Distribution',nbins=24,text_auto=True)\n",
    "\n",
    "# Change the color of the distribution bars\n",
    "color_sequence = ['#1f77b4'] * 24  # You can replace this with your preferred color or use a different color sequence\n",
    "fig.update_traces(marker=dict(color=color_sequence))\n",
    "\n",
    "# Rename x-axis and y-axis titles\n",
    "fig.update_xaxes(title_text=\"Average Score\",range=[6.0, 10])\n",
    "fig.update_yaxes(title_text=\"Count of Reviews\")\n",
    "\n",
    "# Center the title\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Review Average Score Distribution\", font=dict(size=20, color='black')),\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f6d05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"Country\", title='Reviews distribution in each Country',text_auto=True)\n",
    "\n",
    "# Sort bars based on values\n",
    "sorted_countries = df['Country'].value_counts().index\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=sorted_countries)\n",
    "\n",
    "# Change the color of each bar\n",
    "color_sequence = px.colors.qualitative.Set1  # You can choose a different color sequence\n",
    "fig.update_traces(marker=dict(color=color_sequence))\n",
    "\n",
    "# Rename x-axis and y-axis titles\n",
    "fig.update_xaxes(title_text=\"Country\")\n",
    "fig.update_yaxes(title_text=\"Count of Reviews\")\n",
    "\n",
    "# Center the title\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Reviews distribution in each Country\", font=dict(size=20, color='black')),\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4788d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df, x=\"Review Year\", title='Year wise Reviews distribution',text_auto=True)\n",
    "\n",
    "# Sort bars based on values\n",
    "sorted_countries = df['Review Year'].value_counts().index\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=sorted_countries)\n",
    "\n",
    "# Change the color of each bar\n",
    "color_sequence = px.colors.qualitative.Set1  # You can choose a different color sequence\n",
    "fig.update_traces(marker=dict(color=color_sequence))\n",
    "\n",
    "# Rename x-axis and y-axis titles\n",
    "fig.update_xaxes(title_text=\"Review Year\")\n",
    "fig.update_yaxes(title_text=\"Count of Reviews\")\n",
    "\n",
    "# Center the title\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Year wise Reviews distribution\", font=dict(size=20, color='black')),\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a6e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df\n",
    "hotels_avgscore = df1.groupby('Hotel_Address')['Average_Score'].mean().reset_index(name=\"Avg Score\")\n",
    "hotels_avgscore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21327ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.merge(df1, hotels_avgscore, on='Hotel_Address')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.loc[:, ['Hotel_Name','Average_Score','City','lat','lng','City_Latitude','City_Longitude','Avg Score']]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h = df3.groupby(by=[\"Hotel_Name\", \"lat\",\"lng\",\"Avg Score\"]).size().reset_index(name=\"Hotel Count\")\n",
    "df_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_name = df_h['Hotel_Name']\n",
    "lat = df_h['lat']\n",
    "lng = df_h['lng']\n",
    "ag_score = df_h['Avg Score']\n",
    "ht_count = df_h['Hotel Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194091e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install below library if you haven't done\n",
    "#!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08381c33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster, MiniMap, Fullscreen \n",
    " \n",
    "city_data = {\n",
    "    'Hotel_Name': ht_name,\n",
    "    'Latitude': lat,\n",
    "    'Longitude': lng,\n",
    "    'Avg_Rating': ag_score,\n",
    "    'HotelCount': ht_count,\n",
    "}\n",
    "\n",
    "fixed_radius = 10\n",
    "# Create a Folium map centered around the first hotel\n",
    "map_center = [48.7784485, 9.1800132]\n",
    "my_map = folium.Map(location=map_center, zoom_start=5)\n",
    "\n",
    "# Create a MarkerCluster layer\n",
    "marker_cluster = MarkerCluster().add_to(my_map)\n",
    "\n",
    "# Add markers for each hotel with a fixed radius\n",
    "for i in range(len(city_data['Hotel_Name'])):\n",
    "    folium.CircleMarker(\n",
    "        location=[city_data['Latitude'][i], city_data['Longitude'][i]],#I have added stuttgart location so that all cities cover\n",
    "        radius=fixed_radius,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"{city_data['Hotel_Name'][i]} - {city_data['Avg_Rating'][i]} Avg rating - {city_data['HotelCount'][i]} Reviews\"\n",
    "    ).add_to(marker_cluster)\n",
    "    \n",
    "# Add layer control for better interactivity\n",
    "folium.LayerControl().add_to(my_map)\n",
    " \n",
    "# Add a minimap for better navigation\n",
    "minimap = MiniMap(toggle_display=True)\n",
    "my_map.add_child(minimap)\n",
    " \n",
    "# Add fullscreen button for full-screen mode\n",
    "Fullscreen().add_to(my_map)\n",
    " \n",
    "# Save the map as an HTML file\n",
    "my_map.save(\"hotels_data_map.html\")\n",
    " \n",
    "# Display the map directly in the notebook\n",
    "my_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ae1df",
   "metadata": {},
   "source": [
    "<a id=\"16\"></a> \n",
    "### 1.6 Data Preparation for sentiment Analysis (Stop words removal, special characters removal and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607647f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 Data Preparation for Sentiment Analysis\n",
    "# Tokenization and stop words removal\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea9de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_remove_stopwords(text):\n",
    "    tokens = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7406e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tokenized_Review'] = df['Cleaned_Review'].apply(tokenize_and_remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227fe54e",
   "metadata": {},
   "source": [
    "<a id=\"17\"></a> \n",
    "### 1.7 Sentiment Analysis: NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69518b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# Initialize the VADER sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce32b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the sentiment analyzer to each review\n",
    "df['NLTK_Sentiment_Score'] = df['Cleaned_Review'].apply(lambda x: sid.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ab4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize the sentiment scores into positive, neutral, and negative\n",
    "df['NLTK_Sentiment_Label'] = df['NLTK_Sentiment_Score'].apply(lambda x: 'Positive' if x > 0 else ('Neutral' if x == 0 else 'Negative'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12b59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21920c3",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "## Part 2: Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1bbce",
   "metadata": {},
   "source": [
    "<a id=\"21\"></a> \n",
    "### 2.1 Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559b75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6250511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c37c0e",
   "metadata": {},
   "source": [
    "<a id=\"22\"></a> \n",
    "### 2.2 Use the same reviews dataset as the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_documents = df['Positive_Review'].tolist()\n",
    "neg_documents = df['Negative_Review'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f86eec",
   "metadata": {},
   "source": [
    "<a id=\"23\"></a> \n",
    "### 2.3 Preprocess the reviews data (removing stop words, tokenization,stemming, and lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36601488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddbf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_documents = [preprocess_text(doc) for doc in pos_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7225b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd08ec",
   "metadata": {},
   "source": [
    "<a id=\"24\"></a> \n",
    "### 2.4 Latent Dirichlet Allocation - LDA Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0e0a6e",
   "metadata": {},
   "source": [
    "<a id=\"241\"></a> \n",
    "#### A. Positive Reviews - LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9812ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model (As the data is more it is going to take more than 17 minutes to run the below model building)\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a227f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topics\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2cdbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud for all top 5 Positive topics\n",
    "num_topics = 5\n",
    "def get_all_topic_words(lda_model, dictionary, num_topics):\n",
    "    all_topic_words = []\n",
    "    for i in range(num_topics):\n",
    "        topic_terms = lda_model.print_topics(num_topics)[i][1]\n",
    "        topic_terms = topic_terms.split('\"')[1::2]  # Extracting terms between double quotes\n",
    "        all_topic_words.extend(topic_terms)\n",
    "    return all_topic_words\n",
    "\n",
    "def generate_wordcloud(all_topic_words):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(all_topic_words))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for Top 5 Positive Topics')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "all_topic_words = get_all_topic_words(lda_model, dictionary, num_topics)\n",
    "generate_wordcloud(all_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181baf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_GP = [\"Hotel Location and Accessibility\",\"Room Amenities and Services\",\"Room Comfort and Cleanliness\",\"Staff and Service Excellence\",\"Overall Hotel Experience\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb83e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wordcloud for each Positive topic\n",
    "num_topics = 5\n",
    "def get_topic_words(lda_model, dictionary, num_topics):\n",
    "    topic_words = {}\n",
    "    for i in range(num_topics):\n",
    "        topic_terms = lda_model.print_topics(num_topics)[i][1]\n",
    "        topic_terms = topic_terms.split('\"')[1::2]  # Extracting terms between double quotes\n",
    "        topic_words[f'Topic {i + 1}'] = topic_terms\n",
    "    return topic_words\n",
    "\n",
    "def generate_wordcloud(topic_words):\n",
    "    i=0\n",
    "    for topic, terms in topic_words.items():\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(terms))\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Word Cloud for topic: {topic_name_GP[i]}')\n",
    "        plt.show()\n",
    "        i = i+1\n",
    "\n",
    "# Example usage\n",
    "topic_words = get_topic_words(lda_model, dictionary, num_topics)\n",
    "generate_wordcloud(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9cfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Positive Reviews from the data for the above topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196affb",
   "metadata": {},
   "source": [
    "<a id=\"242\"></a> \n",
    "#### B. Negative Reviews - LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1aceec",
   "metadata": {},
   "source": [
    "###### Pre processing the data for Negative Reviews Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_documents1 = [preprocess_text(doc) for doc in neg_documents]\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary1 = corpora.Dictionary(processed_documents1)\n",
    "corpus1 = [dictionary.doc2bow(doc) for doc in processed_documents1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf149c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model (As the data is more it is going to take more than 30 minutes to run the below model building)\n",
    "lda_model_GN = gensim.models.LdaModel(corpus1, num_topics=5, id2word=dictionary1, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topics\n",
    "topics = lda_model_GN.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad9eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud for all top 5 Positive topics\n",
    "num_topics = 5\n",
    "def get_all_topic_words(lda_model_GN, dictionary1, num_topics):\n",
    "    all_topic_words = []\n",
    "    for i in range(num_topics):\n",
    "        topic_terms = lda_model_GN.print_topics(num_topics)[i][1]\n",
    "        topic_terms = topic_terms.split('\"')[1::2]  # Extracting terms between double quotes\n",
    "        all_topic_words.extend(topic_terms)\n",
    "    return all_topic_words\n",
    "\n",
    "def generate_wordcloud(all_topic_words):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(all_topic_words))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for Top 5 Negative Topics')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "all_topic_words = get_all_topic_words(lda_model_GN, dictionary1, num_topics)\n",
    "generate_wordcloud(all_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_GN = [\"Reservation and Booking Concerns\",\"Room Quality and Maintenance Issues\",\"Guest Feedback: Cost and Value\",\"Property Issues\",\"Service and Communication\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca71608",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wordcloud for each Positive topic\n",
    "num_topics = 5\n",
    "def get_topic_words(lda_model_GN, dictionary1, num_topics):\n",
    "    topic_words = {}\n",
    "    for i in range(num_topics):\n",
    "        topic_terms = lda_model_GN.print_topics(num_topics)[i][1]\n",
    "        topic_terms = topic_terms.split('\"')[1::2]  # Extracting terms between double quotes\n",
    "        topic_words[f'Topic {i + 1}'] = topic_terms\n",
    "    return topic_words\n",
    "\n",
    "def generate_wordcloud(topic_words):\n",
    "    i=0\n",
    "    for topic, terms in topic_words.items():\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(terms))\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Word Cloud for topic: {topic_name_GN[i]}')\n",
    "        plt.show()\n",
    "        i=i+1\n",
    "\n",
    "# Example usage\n",
    "topic_words = get_topic_words(lda_model_GN, dictionary1, num_topics)\n",
    "generate_wordcloud(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a162926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd774948",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    "## Part 3: Deep dive into particular hotel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1c1238",
   "metadata": {},
   "source": [
    "<a id=\"31\"></a> \n",
    "### 3.1 Based on EDA Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92109c0",
   "metadata": {},
   "source": [
    "Choosen \"Park Plaza Westminster Bridge London\" Hotel to deep dive and check the sentiment and topics in both the \"Positive\" and \"Negative Reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dc8cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch = df.loc[df['Hotel_Name'] == \"Park Plaza Westminster Bridge London\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_ch, x=\"Review Year\", title='Year wise Reviews distribution for Park Plaza Westminster Bridge London',text_auto=True)\n",
    "\n",
    "# Sort bars based on values\n",
    "sorted_countries = df_ch['Review Year'].value_counts().index\n",
    "fig.update_xaxes(categoryorder='array', categoryarray=sorted_countries)\n",
    "\n",
    "# Change the color of each bar\n",
    "color_sequence = px.colors.qualitative.Set1  # You can choose a different color sequence\n",
    "fig.update_traces(marker=dict(color=color_sequence))\n",
    "\n",
    "# Rename x-axis and y-axis titles\n",
    "fig.update_xaxes(title_text=\"Review Year\")\n",
    "fig.update_yaxes(title_text=\"Count of Reviews\")\n",
    "\n",
    "# Center the title\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Year wise Reviews distribution\", font=dict(size=20, color='black')),\n",
    "    title_x=0.5,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bcad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ch = df_ch.iloc[:,0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1f4e2",
   "metadata": {},
   "source": [
    "<a id=\"32\"></a> \n",
    "### 3.2 Data prepration on \"Park Plaza Westminster Bridge London\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011ce1d1",
   "metadata": {},
   "source": [
    "#### Data Cleaning and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552b3445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b3881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Cleaning the data\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9953da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning to reviews\n",
    "df_ch['Cleaned_Positive_Review'] = df_ch['Positive_Review'].apply(clean_text)\n",
    "df_ch['Cleaned_Negative_Review'] = df_ch['Negative_Review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2021b120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ch.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f069600",
   "metadata": {},
   "source": [
    "<a id=\"33\"></a> \n",
    "### 3.3 Topic Modelling on subset data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a98bb",
   "metadata": {},
   "source": [
    "<a id=\"331\"></a> \n",
    "#### A. Positive Reviews Data preparation for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reviews with \"No Positive\" as the review (around 290)\n",
    "print(df_ch.shape)\n",
    "TM_Pos = df_ch.loc[df_ch['Positive_Review'] != \"No Positive\"]\n",
    "print(TM_Pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_hp = TM_Pos['Positive_Review'].tolist()\n",
    "\n",
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f349b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec15c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_documents = [preprocess_text(doc) for doc in documents_hp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee340e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab15767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model (As the data is more it is going to take more than 30 minutes to run the below model building)\n",
    "lda_model_HP = gensim.models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a3ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the topics\n",
    "topics = lda_model_HP.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89624d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud for all top 5 Positive topics\n",
    "num_topics = 5\n",
    "def get_all_topic_words(lda_model_HP, dictionary, num_topics):\n",
    "    all_topic_words = []\n",
    "    for i in range(num_topics):\n",
    "        topic_terms = lda_model_HP.print_topics(num_topics)[i][1]\n",
    "        topic_terms = topic_terms.split('\"')[1::2]  # Extracting terms between double quotes\n",
    "        all_topic_words.extend(topic_terms)\n",
    "    return all_topic_words\n",
    "\n",
    "def generate_wordcloud(all_topic_words):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(all_topic_words))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for Top 5 Positive Topics')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "all_topic_words = get_all_topic_words(lda_model_HP, dictionary, num_topics)\n",
    "generate_wordcloud(all_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f9b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_HP = [\"Hotel Service & Management\",\"Room Ambience\",\"Room Features\",\"Delicious Food\",\"Exceptional Amenities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c44e1a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wordcloud for each Positive topic\n",
    "num_topics = 5\n",
    "def get_topic_words(lda_model_HP, dictionary, num_topics):\n",
    "    topic_words = {}\n",
    "    for i in range(num_topics):\n",
    "        topic_terms = lda_model_HP.print_topics(num_topics)[i][1]\n",
    "        topic_terms = topic_terms.split('\"')[1::2]  # Extracting terms between double quotes\n",
    "        topic_words[f'Topic {i + 1}'] = topic_terms\n",
    "    return topic_words\n",
    "\n",
    "def generate_wordcloud(topic_words):\n",
    "    i=0\n",
    "    for topic, terms in topic_words.items():\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(terms))\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Word Cloud for topic: {topic_name_HP[i]}')\n",
    "        plt.show()\n",
    "        i=i+1\n",
    "\n",
    "# Example usage\n",
    "topic_words = get_topic_words(lda_model_HP, dictionary, num_topics)\n",
    "generate_wordcloud(topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155205f9",
   "metadata": {},
   "source": [
    "<a id=\"332\"></a> \n",
    "#### B. Negative Reviews Data preparation for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55482b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove reviews with \"No Negatives\" as the review (around 290)\n",
    "# remove reviews with \"No Positive\" as the review (around 290)\n",
    "print(df_ch.shape)\n",
    "TM_Neg1 = df_ch.loc[df_ch['Negative_Review'] != \"No Negative\"]\n",
    "print(TM_Neg1.shape)\n",
    "TM_Neg2 = TM_Neg1.loc[TM_Neg1['Negative_Review'] != \" No negatives just a little confused as to where lifts were located when leaving room maybe a marker on carpet to indicate direction \"]\n",
    "print(TM_Neg2.shape)\n",
    "TM_Neg3 = TM_Neg2.loc[TM_Neg2['Negative_Review'] != \" No negatives \"]\n",
    "print(TM_Neg3.shape)\n",
    "TM_Neg4 = TM_Neg3.loc[TM_Neg3['Negative_Review'] != \" All good no negatives\"]\n",
    "print(TM_Neg4.shape)\n",
    "TM_Neg5 = TM_Neg4.loc[TM_Neg4['Negative_Review'] != \" No negatives at all of any note\"]\n",
    "print(TM_Neg5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_neg = TM_Neg5['Negative_Review'].tolist()\n",
    "\n",
    "# Preprocess the data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee54cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_documents2 = [preprocess_text(doc) for doc in documents_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f38bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and corpus for LDA\n",
    "dictionary2 = corpora.Dictionary(processed_documents2)\n",
    "corpus2 = [dictionary.doc2bow(doc) for doc in processed_documents2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461d294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model (As the data is more it is going to take more than 30 minutes to run the below model building)\n",
    "lda_model_hn = gensim.models.LdaModel(corpus2, num_topics=5, id2word=dictionary2, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63c12c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the topics\n",
    "topics = lda_model_hn.print_topics(num_words=10)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_terms = lda_model_hn.print_topics(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ca50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud for top 5 negative topics\n",
    "num_topics = 5\n",
    "def get_all_topic_words(lda_model_hn, dictionary2, num_topics):\n",
    "    all_topic_words = []\n",
    "    for i in range(num_topics):\n",
    "        topic_terms = lda_model_hn.print_topics(num_topics)[i][1]\n",
    "        topic_terms = topic_terms.split('\"')[1::2]  # Extracting terms between double quotes\n",
    "        all_topic_words.extend(topic_terms)\n",
    "    return all_topic_words\n",
    "\n",
    "def generate_wordcloud(all_topic_words):\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(all_topic_words))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud for Top 5 Negative Topics')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "all_topic_words = get_all_topic_words(lda_model_hn, dictionary2, num_topics)\n",
    "generate_wordcloud(all_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_HN = [\"Check-in Challenges and Service Shortcomings\",\"Room Quality and Maintenance Issues\",\"Guest Feedback: Cost and Value\",\"Property Issues\",\"Service and Communication\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a92ae6a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Wordcloud for each negative topic\n",
    "num_topics = 5\n",
    "def get_topic_words(lda_model_hn, dictionary2, num_topics):\n",
    "    topic_words = {}\n",
    "    for i in range(num_topics):\n",
    "        topic_terms = lda_model_hn.print_topics(num_topics)[i][1]\n",
    "        topic_terms = topic_terms.split('\"')[1::2]  # Extracting terms between double quotes\n",
    "        topic_words[f'Topic {i + 1}'] = topic_terms\n",
    "    return topic_words\n",
    "\n",
    "def generate_wordcloud(topic_words):\n",
    "    i=0\n",
    "    for topic, terms in topic_words.items():\n",
    "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(terms))\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Word Cloud for topic: {topic_name_HN[i]}')\n",
    "        plt.show()\n",
    "        i=i+1\n",
    "\n",
    "# Example usage\n",
    "topic_words = get_topic_words(lda_model_hn, dictionary2, num_topics)\n",
    "generate_wordcloud(topic_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540bb1e",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> \n",
    "## Part 4: Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d8729",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "Based detailed analysis on the complete 'Europe hotels reviews data' reveals a predominance of perfect scores, suggesting overall excellent guest experiences, with significantly more words used in negative reviews than in positive ones. The Ritz Paris leads the top-rated hotels, showcasing exemplary service. Over time, hotel scores have consistently averaged between 8.3 and 8.4.\n",
    "\n",
    "**LDA Topics:**\n",
    "\n",
    "*Positive topics:*\n",
    "1. Hotel Location and Accessibility\n",
    "2. Room Amenities and Services\n",
    "3. Room Comfort and Cleanliness\n",
    "4. Staff and Service Excellence\n",
    "5. Overall Hotel Experience\n",
    "\n",
    "*Negative Topics:*\n",
    "1. Reservation and Booking Concerns\n",
    "2. Room Quality and Maintenance\n",
    "3. Guest Experiences with Staff and Service\n",
    "4. Issues Related to Hotel Facilities and Services\n",
    "5. Specific Complaints and Negative Incidents\n",
    "\n",
    "**Suggestions based on complete Analysis:**\n",
    "*Service Improvement:* Address booking concerns and room quality issues while enhancing staff training for more personalized service based on guest feedback.\n",
    "*Marketing and Branding:* Leverage positive feedback on \"Staff and Service Excellence\" and \"Overall Hotel Experience,\" and highlight \"Hotel Location and Accessibility\" in  marketing strategy.\n",
    "*Customer Experience Design:* Improve room amenities and services to boost guest satisfaction, and address specific issues mentioned in negative reviews to prevent future problems.\n",
    "*Competitive Analysis:* Compare the top-performing hotels' scores and reviews with the average to identify best practices that can be adopted or adapted.\n",
    "*Operational Adjustments:* Use the temporal analysis to prepare for peak times with higher guest expectations and manage off-peak times more efficiently.\n",
    "*Reputation Management:* Address negative reviews proactively by reaching out to dissatisfied guests and offering resolutions, which can also improve online ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff5043a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
